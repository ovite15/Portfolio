{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":71609,"databundleVersionId":7833551,"sourceType":"competition"},{"sourceId":7739654,"sourceType":"datasetVersion","datasetId":4523649}],"dockerImageVersionId":30665,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q simpletransformers","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport json\nfrom datasets import load_dataset","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lst20 = load_dataset(\"lst20\", data_dir=\"/kaggle/input/lst20-corpus/LST20_Corpus\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = pd.DataFrame(lst20['train'])\nvalidation_df = pd.DataFrame(lst20['validation'])\ntest_df = pd.DataFrame(lst20['test'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"NER_TAGS = [\n       \"O\",\n        \"B_BRN\",        \"B_DES\",        \"B_DTM\",        \"B_LOC\",        \"B_MEA\",        \"B_NUM\",        \"B_ORG\",        \"B_PER\",        \"B_TRM\",        \"B_TTL\",\n       \"I_BRN\",        \"I_DES\",        \"I_DTM\",        \"I_LOC\",        \"I_MEA\",        \"I_NUM\",        \"I_ORG\",        \"I_PER\",        \"I_TRM\",        \"I_TTL\",\n        \"E_BRN\",        \"E_DES\",        \"E_DTM\",        \"E_LOC\",        \"E_MEA\",        \"E_NUM\",        \"E_ORG\",        \"E_PER\",        \"E_TRM\",        \"E_TTL\"]\nprint(NER_TAGS)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_filter = ['id', 'tokens', 'ner_tags']\ntrain_df = train_df[df_filter]\nvalidation_df = validation_df[df_filter]\ntest_df = test_df[df_filter]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def convert_data_to_df(df):\n  data_df = pd.DataFrame()\n  sentence_id = []\n  words = []\n  labels = []\n\n  for sentence in range(len(df)):\n    for token in range(len(df['tokens'][sentence])):\n      sentence_id.append(sentence)\n      words.append(df['tokens'][sentence][token])\n      labels.append(NER_TAGS[df['ner_tags'][sentence][token]]) #Map 0 to \"O\", 1 to \"B_BRN\"\n\n  return pd.DataFrame(\n      {\"sentence_id\": sentence_id, \"words\": words, \"labels\": labels}\n  )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data = convert_data_to_df(train_df)\n#Re-process to validate and test dataset\neval_data = convert_data_to_df(validation_df )\ntest_data = convert_data_to_df(test_df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nimport logging\nfrom simpletransformers.ner import NERModel, NERArgs\nimport torch\n\n# Simple Transformer https://simpletransformers.ai/docs/ner-minimal-start/\nlogging.basicConfig(level=logging.INFO)\ntransformers_logger = logging.getLogger(\"transformers\")\ntransformers_logger.setLevel(logging.WARNING)\n\nner_args = NERArgs()\nner_args.train_batch_size = 202 #192 is fit for GPU T4, 512 for A100\nner_args.use_multiprocessing = True\nner_args.evaluate_during_training = True\nner_args.eval_batch_size = 202\nner_args.num_train_epochs = 20\nner_args.max_seq_length = 81\nner_args.overwrite_output_dir = True","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = NERModel(\n     \"camembert\", # Model Type\n     \"pythainlp/thainer-corpus-v2-base-model \",  #Ner Pre-trained Model\n     args=ner_args, use_cuda=torch.cuda.is_available(), labels=NER_TAGS , ignore_mismatched_sizes=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.train_model(train_data, eval_data=eval_data)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"result, model_outputs, preds_list = model.eval_model(eval_data)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(result)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"texts_test = pd.read_csv('/kaggle/input/nithan-chadok-name-entity-recognition/test.csv')\ntexts_test_raw = texts_test['word'].tolist()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def blank_space(x):\n  if x == '':\n    x = '_'\n  return x\n\n#Loop replace blank to \"_\"\nfor i in range(len(texts_test_raw)):\n  texts_test_raw[i] = blank_space(texts_test_raw[i])\n\ndef split_into_sentences(tokens, tokens_per_sentence=20):\n    sentences = []\n    for i in range(0, len(tokens), tokens_per_sentence):\n        sentence = tokens[i:i+tokens_per_sentence]\n        sentences.append(sentence)\n    return sentences\n\nmy_token = split_into_sentences(texts_test_raw)\ndef data_inside(data_list):\n  x = 0\n  for i in range(len(data_list)):\n    a = len(data_list[i])\n    x = x+a\n  return x\n\nmy_token_list = []\nfor i in range(len(my_token)):\n  sent_join = ' '.join(my_token[i])\n  print(sent_join)\n  my_token_list.append(sent_join)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions, raw_outputs = model.predict(my_token, False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_test_df = []\nfor i in range(len(predictions)):\n# for i in range(3):\n  for j in range(len(predictions[i])):\n    data = predictions[i][j]\n    value = data.values()\n    final_test_df += value\n\nfinal_result = pd.DataFrame(final_test_df)\ndata = {\n    'New_id': [\n        0, 1, 2, 3, 4, 5, 6, 7, 8, 9,\n        10, 11, 12, 13, 14, 15, 16, 17, 18, 19,\n        20, 21, 22, 23, 24, 25, 26, 27, 28, 29,\n        30, 31\n    ],\n    'New_tag': [\n        'O', 'B_ORG', 'B_PER', 'B_LOC', 'B_MEA', 'I_DTM', 'I_ORG', 'E_ORG', 'I_PER', 'B_TTL',\n        'E_PER', 'B_DES', 'E_LOC', 'B_DTM', 'B_NUM', 'I_MEA', 'E_DTM', 'E_MEA', 'I_LOC', 'I_DES',\n        'E_DES', 'I_NUM', 'E_NUM', 'B_TRM', 'B_BRN', 'I_TRM', 'E_TRM', 'I_TTL', 'I_BRN', 'E_BRN',\n        'E_TTL', 'B_NAME'\n    ]\n}\n# Create DataFrame\ntag_df = pd.DataFrame(data)\nfinal_result['New_id'] = final_result[0].map(tag_df.set_index('New_tag')['New_id'])\nsubmisstion_df = pd.read_csv('/kaggle/input/nithan-chadok-name-entity-recognition/sample_submission.csv')\nsubmisstion_df['token'] = pd.DataFrame({'Token': texts_test_raw})\nsubmisstion_df['Final_pred'] = pd.DataFrame({'Final_pred': final_test_df})\nsubmisstion_df['Predicted'] = final_result['New_id']\nsubmission_df = submisstion_df[['i','Predicted']]\nsubmission_df = submission_df.rename(columns={'Predicted': 'pred'})\nsubmission_df = submission_df.set_index('i')\nsubmission_df.to_csv(\"submission3.csv\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}