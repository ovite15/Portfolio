{"cells":[{"cell_type":"markdown","metadata":{},"source":["****Import module****"]},{"cell_type":"markdown","metadata":{},"source":["* THANKS \n","1. REF: https://github.com/Konthee/superai-3-Image-NER\n","1. REF: https://colab.research.google.com/drive/1-wrZmCyP9BQNG75fbY1XT0GHfHOcZztI?usp=sharing"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"outputs":[],"source":["!pip -q install transformers\n","!pip -q install datasets\n","!pip -q install simpletransformers\n","!pip -q install python-crfsuite\n","!pip -q install pytesseract\n","!pip -q install deskew\n","!sudo apt-get install  tesseract-ocr libtesseract-dev tesseract-ocr-tha"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import cv2\n","import PIL\n","from PIL import Image\n","from PIL import ImageDraw\n","import os\n","import tensorflow as tf\n","import matplotlib.pyplot as plt\n","import matplotlib.gridspec as gridspec\n","import time\n","import numpy as np\n","import seaborn as sns\n","import pandas as pd\n","import shutil\n","\n","from tqdm import tqdm\n","from tqdm.notebook import trange, tqdm\n","import pytesseract\n","import re\n","import seaborn as sns\n","sns.set_theme()\n","from deskew import determine_skew"]},{"cell_type":"markdown","metadata":{},"source":["# OCR"]},{"cell_type":"markdown","metadata":{},"source":["Skew correction / deskew"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Rotate the image around its center\n","def rotateImage(cvImage, angle: float):\n","    newImage = cvImage.copy()\n","    (h, w) = newImage.shape[:2]\n","    center = (w // 2, h // 2)\n","    M = cv2.getRotationMatrix2D(center, angle, 1.0)\n","    newImage = cv2.warpAffine(newImage, M, (w, h), flags=cv2.INTER_CUBIC, borderMode=cv2.BORDER_REPLICATE)\n","    return newImage\n","\n","# Deskew image\n","def deskew(cvImage):\n","    angle = determine_skew(cvImage)\n","    return rotateImage(cvImage, angle)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["kernel_sharp = np.array([[0,-1,0],\n","                         [-1,5,-1],\n","                         [0,-1,0]],dtype=np.float32)"]},{"cell_type":"markdown","metadata":{},"source":["Create folder with cut images"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["path_image_cut= 'image_cut'\n","path_image = '/content/images/images'\n","try: shutil.rmtree(path_image_cut)\n","except : pass\n","#Create Folder\n","os.mkdir(path_image_cut)\n","\n","\n","kernel_sharp = np.array([[0,-1,0],\n","                   [-1,5,-1],\n","                   [0,-1,0]],dtype=np.float32)\n","num = 0\n","list_ = []\n","for index in range(len(os.listdir(path_image))):\n","    img = cv2.imread(f'{path_image}/{index:05d}.jpg',cv2.IMREAD_GRAYSCALE)\n","    img = cv2.filter2D(img,-1,kernel_sharp)\n","    img = cv2.fastNlMeansDenoising(img, None, 10, 7, 21)\n","    deskew_ = deskew(img)\n","    imgresize2 = deskew_.copy()\n","    gray_blur = cv2.GaussianBlur(deskew_,(5,5),0)\n","    thresh=cv2.threshold(gray_blur, 180, 255, cv2.THRESH_BINARY +cv2.THRESH_OTSU)[1]\n","    kernel=np.ones((6,15),np.uint8)\n","    closing = cv2.erode(deskew_,kernel,iterations = 2)\n","    result_img=closing.copy()\n","\n","    contours,hierachy=cv2.findContours(result_img,cv2.RETR_LIST,cv2.CHAIN_APPROX_SIMPLE)\n","    # w,h= result_img.shape\n","\n","    # print(index)\n","    contours = contours[:-1][::-1]\n","    # print(len(contours),index)\n","    if len(contours) != 14:\n","      list_ += [index]\n","      while len(contours) < 14:\n","        new = np.array(contours[-1],dtype=np.int32)\n","        contours += (new,)\n","\n","\n","    print(len(contours),index)\n","    num = 14 *index\n","    for i, cnt in enumerate(contours):\n","        (x,y,w,h)= cv2.boundingRect(cnt)\n","        result = imgresize2[y:y+h,x:x+w]\n","        h_,w_ = result.shape\n","\n","\n","        result = cv2.fastNlMeansDenoising(result, None, 20, 7, 21)\n","        result = cv2.resize(result, (w_*8,h_*8), interpolation = cv2.INTER_AREA)\n","        result = cv2.GaussianBlur(result,(9 , 9),0)\n","        result = cv2.filter2D(result,-1,kernel_sharp)\n","        result=cv2.threshold(result,180,255,cv2.THRESH_OTSU)[1]\n","        kernel = cv2.getStructuringElement(cv2.MORPH_RECT,(2,2))\n","        result = cv2.dilate(result,kernel,iterations = 3)\n","\n","\n","        cv2.imwrite(path_image_cut+'/{:05d}.jpg'.format(num),result)\n","        num += 1\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import pytesseract\n","print(pytesseract.get_tesseract_version())\n","print(pytesseract.get_languages())"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def clean_data(txt,j):\n","    txt=txt.replace('\\n','')\n","    txt=txt.replace('|','')\n","\n","    if \",\"  in txt:\n","        txt=txt[txt.index(',')+1:]\n","    elif '.' in txt:\n","        txt=txt[txt.index('.')+1:]\n","    elif ' ' in txt :\n","        txt=txt[txt.index(' ')+1:]\n","    elif ':' in txt :\n","        txt=txt[txt.index(':')+1:]\n","\n","    elif str(j) in txt :\n","        txt=txt[txt.index(str(j))+1:]\n","\n","    txt=txt.replace(' ','')\n","    txt=txt.replace('-','')\n","    txt=txt.replace('๕','&')\n","\n","    text=re.findall(\"[ก-๙]+\", txt)\n","    num=re.findall(\"[0-9]+\", txt)\n","    if (len(text) == len(num) != 0)  :\n","        txt=text[0]\n","    elif len(text) ==0 and len(num) >0 :\n","        if str(j) not in txt :\n","            txt=num[0]\n","        else : txt= '_'\n","\n","    if txt == '':\n","        txt ='_'\n","    return txt"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["path_image_cut = '/content/image_cut4'\n","df_test = pd.DataFrame({\"Id\" : [], \"Text\" : []})"]},{"cell_type":"markdown","metadata":{},"source":["add word in dataframe"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["n=0\n","n+=1\n","import cv2\n","path_image_cut = '/content/image_cut4'\n","for j in range(len(os.listdir(path_image_cut))):\n","    local = path_image_cut + r'/{:05d}.jpg'.format(j)\n","    img = Image.open(local)\n","    txt = pytesseract.image_to_string(local, lang='tha',config='--psm 8') # --psm 13 --psm 8\n","    txt= clean_data(txt,j)\n","    df_test=df_test.append({\"Id\" : i, \"Text\" : txt}, ignore_index=True)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df_new = df_test.copy()\n","df_new = df_new.reset_index()\n","df_new = df_new.drop('Id',axis = 1)\n","df_new = df_new.rename(columns={'index':'Id'})"]},{"cell_type":"markdown","metadata":{},"source":["# Tags NER"]},{"cell_type":"markdown","metadata":{},"source":["Train model"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import pandas as pd\n","import json\n","from datasets import load_dataset\n","PYTORCH_NO_CUDA_MEMORY_CACHING=1\n","\n","lst20 = load_dataset(\"lst20\", data_dir=\"/home/sivakorn/NER/AIFORTHAI/LST20_Corpus\")\n","train_df = pd.DataFrame(lst20['train'])\n","validation_df = pd.DataFrame(lst20['validation'])\n","test_df = pd.DataFrame(lst20['test'])\n","\n","\n","#Column Filter only NER Tags\n","df_filter = ['id', 'tokens', 'ner_tags']\n","train_df = train_df[df_filter]\n","validation_df = validation_df[df_filter]\n","test_df = test_df[df_filter]\n","\n","\n","# Define Ner Tags replace missing ne_list.txt\n","NER_TAGS = [\n","       \"O\",\n","        \"B_BRN\",        \"B_DES\",        \"B_DTM\",        \"B_LOC\",        \"B_MEA\",        \"B_NUM\",        \"B_ORG\",        \"B_PER\",        \"B_TRM\",        \"B_TTL\",\n","       \"I_BRN\",        \"I_DES\",        \"I_DTM\",        \"I_LOC\",        \"I_MEA\",        \"I_NUM\",        \"I_ORG\",        \"I_PER\",        \"I_TRM\",        \"I_TTL\",\n","        \"E_BRN\",        \"E_DES\",        \"E_DTM\",        \"E_LOC\",        \"E_MEA\",        \"E_NUM\",        \"E_ORG\",        \"E_PER\",        \"E_TRM\",        \"E_TTL\"]\n","\n","def convert_data_to_df(df):\n","  data_df = pd.DataFrame()\n","  sentence_id = []\n","  words = []\n","  labels = []\n","\n","  for sentence in range(len(df)):\n","    for token in range(len(df['tokens'][sentence])):\n","      sentence_id.append(sentence)\n","      words.append(df['tokens'][sentence][token])\n","      labels.append(NER_TAGS[df['ner_tags'][sentence][token]]) #Map 0 to \"O\", 1 to \"B_BRN\"\n","\n","  return pd.DataFrame(\n","      {\"sentence_id\": sentence_id, \"words\": words, \"labels\": labels}\n","  )\n","\n","train_data = convert_data_to_df(train_df)\n","#Re-process to validate and test dataset\n","eval_data = convert_data_to_df(validation_df )\n","test_data = convert_data_to_df(test_df)\n","#train_data.head(9)\n","\n","import logging\n","from simpletransformers.ner import NERModel, NERArgs\n","import torch\n","\n","\n","#torch.cuda.empty_cache()\n","\n","# Simple Transformer https://simpletransformers.ai/docs/ner-minimal-start/\n","logging.basicConfig(level=logging.INFO)\n","transformers_logger = logging.getLogger(\"transformers\")\n","transformers_logger.setLevel(logging.WARNING)\n","max_seq_length = train_data['words'].str.len().max()\n","\n","ner_args = NERArgs()\n","ner_args.train_batch_size = 128 #192 is fit for GPU T4, 512 for A100\n","ner_args.use_multiprocessing = True\n","ner_args.evaluate_during_training = True\n","ner_args.eval_batch_size = 128\n","ner_args.num_train_epochs = 12\n","ner_args.overwrite_output_dir = True\n","ner_args.gradient_accumulation_steps = 4\n","ner_args.learning_rate = 1e-5\n","\n","model = NERModel(\n","     \"camembert\", # Model Type\n","     \"airesearch/wangchanberta-base-att-spm-uncased\",  #Ner Pre-trained Model\n","     args=ner_args, use_cuda=torch.cuda.is_available(), labels=NER_TAGS,ignore_mismatched_sizes=True) # Local Config\n","\n","\n","model.train_model(train_data, eval_data=eval_data)\n","result, model_outputs, preds_list = model.eval_model(eval_data)\n","print(result)"]},{"cell_type":"markdown","metadata":{},"source":["Prediction"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import logging\n","from simpletransformers.ner import NERModel, NERArgs\n","import torch\n","import pandas as pd \n","texts_test = pd.read_csv('/home/sivakorn/OCR_NER/df_final.csv')\n","#print(texts_test.columns)\n","texts_test['Text'] = texts_test['Text'].replace({ r'\\x0c': '', r'\\n': ''}, regex=True)\n","NER_TAGS = [\n","       \"O\",\n","        \"B_BRN\",        \"B_DES\",        \"B_DTM\",        \"B_LOC\",        \"B_MEA\",        \"B_NUM\",        \"B_ORG\",        \"B_PER\",        \"B_TRM\",        \"B_TTL\",\n","       \"I_BRN\",        \"I_DES\",        \"I_DTM\",        \"I_LOC\",        \"I_MEA\",        \"I_NUM\",        \"I_ORG\",        \"I_PER\",        \"I_TRM\",        \"I_TTL\",\n","        \"E_BRN\",        \"E_DES\",        \"E_DTM\",        \"E_LOC\",        \"E_MEA\",        \"E_NUM\",        \"E_ORG\",        \"E_PER\",        \"E_TRM\",        \"E_TTL\"]\n","\n","\n","texts_test_raw = texts_test['Text'].tolist()\n","def blank_space(x):\n","  if x == '':\n","    x = '_'\n","  return x\n","\n","#Loop replace blank to \"_\"\n","for i in range(len(texts_test_raw)):\n","  texts_test_raw[i] = blank_space(texts_test_raw[i])\n","print(len(texts_test_raw))\n","\n","def data_inside(data_list):\n","  x = 0\n","  for i in range(len(data_list)):\n","    a = len(data_list[i])\n","    x = x+a\n","  return x\n","\n","def split_into_sentences(tokens, tokens_per_sentence=20):\n","    sentences = []\n","    for i in range(0, len(tokens), tokens_per_sentence):\n","        sentence = tokens[i:i+tokens_per_sentence]\n","        sentences.append(sentence)\n","    return sentences\n","\n","\n","my_token = split_into_sentences(texts_test_raw)\n","print(my_token[0:20])\n","print(len(my_token))\n","my_token_list = []\n","\n","for i in range(len(my_token)):\n","  sent_join = ' '.join(str(my_token[i]))\n","  #print(sent_join)\n","  my_token_list.append(sent_join)\n","\n","\n","print(len(my_token))\n","print(len(my_token_list))\n","print(data_inside(my_token_list))\n","\n","\n","ner_args = NERArgs()\n","ner_args.eval_batch_size = 128\n","ner_args.use_multiprocessing = True\n","#ner_args.max_seq_length = 500 # Fixed Requirement ##############################\n","model = NERModel(\n","     \"auto\", \"/home/sivakorn/OCR_NER/AIFORTHAI/outputs/best_model/\", args=ner_args, use_cuda=torch.cuda.is_available(), labels= NER_TAGS  # your latest model\n",")\n","\n","predictions, raw_outputs = model.predict(my_token, False)\n","print(predictions[0][0:6])\n","print(data_inside(predictions))\n","\n","final_test_df = []\n","for i in range(len(predictions)):\n","# for i in range(3):\n","  for j in range(len(predictions[i])):\n","    data = predictions[i][j]\n","    value = data.values()\n","    final_test_df += value\n","\n","final_result = pd.DataFrame(final_test_df)\n","data = {\n","    'New_id': [\n","        0, 1, 2, 3, 4, 5, 6, 7, 8, 9,\n","        10, 11, 12, 13, 14, 15, 16, 17, 18, 19,\n","        20, 21, 22, 23, 24, 25, 26, 27, 28, 29,\n","        30, 31\n","    ],\n","    'New_tag': [\n","        'O', 'B_ORG', 'B_PER', 'B_LOC', 'B_MEA', 'I_DTM', 'I_ORG', 'E_ORG', 'I_PER', 'B_TTL',\n","        'E_PER', 'B_DES', 'E_LOC', 'B_DTM', 'B_NUM', 'I_MEA', 'E_DTM', 'E_MEA', 'I_LOC', 'I_DES',\n","        'E_DES', 'I_NUM', 'E_NUM', 'B_TRM', 'B_BRN', 'I_TRM', 'E_TRM', 'I_TTL', 'I_BRN', 'E_BRN',\n","        'E_TTL', 'B_NAME'\n","    ]\n","}\n","# Create DataFrame\n","tag_df = pd.DataFrame(data)\n","final_result['New_id'] = final_result[0].map(tag_df.set_index('New_tag')['New_id'])\n","submisstion_df = pd.read_csv(\"/home/sivakorn/OCR_NER/sample_submission.csv\")\n","submisstion_df['token'] = pd.DataFrame({'Token': texts_test_raw})\n","submisstion_df['Final_pred'] = pd.DataFrame({'Final_pred': final_test_df})\n","submisstion_df['Predicted'] = final_result['New_id']\n","submission_df = submisstion_df[['Id','Predicted']]\n","submission_df = submission_df.rename(columns={'Predicted': 'pred'})\n","submission_df = submission_df.set_index('Id')\n","\n","submission_df.to_csv(\"/home/sivakorn/OCR_NER/ocr_ner3.csv\")"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":4}
